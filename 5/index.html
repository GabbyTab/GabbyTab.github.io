

<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Filter Fun</title>
    <link rel="stylesheet" href="styles.css">
</head>

    
<body>
    <div class="background-container">
        <div class="image-layer image1"></div>
        <div class="image-layer image2"></div>
        <div class="image-layer image3"></div>
    </div>


    <header id="header">
        <div class="title-image">
            <h1>IMAGE WARPING and MOSAICING</h1>
        </div>
    </header>


    <section id="Overview">
        <h2>Project Overview PART A</h2>
        <p>
            play around with diffusion models, implement diffusion sampling loops, and use them for other tasks such as inpainting and creating optical illusions.  
        </p>
    </section>
    
    <section id="hall-of-fame">
        <h2>Part 0 setup</h2>
               
        <p>
            SEED = 180
        </p>

         <p>
            Running the model on the three text prompts with 20 de noising produces ok results. All three have some form of degeneration, The man is cross eyed, the colors of the painting are wrong, and the rocket ship is very simplistic.
             (I can relate this to the style of the prompt.)
        </p>
        
        <div class="gallery small-gallery">   
            <figure>
                <img src="images/q0a.png" alt="Image 1">
            </figure>
        </div>
        
         <p>
            Running the model at double the number of denoising steps produces significantly better results. This is because...
        </p>

        <div class="gallery small-gallery">   
            <figure>
                <img src="images/q0b.png" alt="Image 1">
            </figure>
        </div>

       
    </section>



    <section id="naive-methods">
        <h2>1.1 Implementing the forward process</h2>

        <p> 
            A key part of diffusion is the forward process, which takes a clean image and adds noise to it. we get a noisy image by sampling and scaling acording to some time schdule. The forward process is not just adding noise, it's also scaling the image.
        </p>

        <p>the test image at noise levels [250, 500, 750]</p>


        <div class="gallery large-gallery">
            <figure>
                <img src="images/1a.png" alt="Image 1">
            </figure>
        </div>

        <h2>Classical Denoising</h2>
      <div class="gallery large-gallery">
            <figure>
                <img src="images/1b.png" alt="Image 1">
            </figure>
        </div>


    <h2>One Step Denoising</h2>
      <div class="gallery large-gallery">
            <figure>
                <img src="images/1c.png" alt="Image 1">
            </figure>
        </div>
        
    </section>

    <h2>Iterative Denoising</h2>
      <div class="gallery large-gallery">
            <figure>
                <img src="images/2a.png" alt="Image 1">
            </figure>
        </div>
        
    </section>


    <section id="speed">
        <h2>Diffusion Model Sampling</h2>

        <p>
        </p>

        <div class="gallery large_gallery">
            <figure>
                <img src="images/3a.png" alt="Image 2">
            </figure>

        </div>
        
        
        <h2>Classifier Free Guidance</h2>

        <p>
        </p>

        <div class="gallery large_gallery">
            <figure>
                <img src="images/3b.png" alt="Image 2">
            </figure>

        </div>

        <h2>Image-to-image Translation</h2>

        <p>
        </p>

        <div class="gallery large_gallery">
            <figure>
                <img src="images/4a.png" alt="Image 2">
            </figure>
        <figure>
                <img src="images/4b.png" alt="Image 2">
            </figure>
        <figure>
                <img src="images/4c.png" alt="Image 2">
            </figure>

        </div>
            
    </section>


       <section id="charicatures">
       <h2>Editing Hand-Drawn and Web Images</h2>

        <p> 
            A key part of diffusion is the forward process, which takes a clean image and adds noise to it. we get a noisy image by sampling and scaling acording to some time schdule. The forward process is not just adding noise, it's also scaling the image.
        </p>

        <div class="gallery large-gallery">
            <figure>
                <img src="images/5a.png" alt="Image 1">
            </figure>
            <figure>
                <img src="images/5b.png" alt="Image 1">
            </figure>
        </div>
           
           <div class="gallery large_gallery">
            <figure>
                <img src="images/5c.png" alt="Image 2">
            </figure>
        <figure>
                <img src="images/5d.png" alt="Image 2">
            </figure>
        <figure>
                <img src="images/5e.png" alt="Image 2">
            </figure>

        </div>
            
    </section>


    
    <section id="speed">
        <h2>Inpainting</h2>
      
        <p> 
            Given an image and a binary mask, we can create a new image that has new content wherever the mask covers. we leave everything inside the edit mask alone, but we replace everything outside the edit mask with our original image -- with the correct amount of noise added for timestep t.
        </p>


        
        <div class="gallery large-gallery">
            <figure>
                <img src="images/6a.png" alt="Image 1">
            </figure>
     
        </div>


        <div class="gallery large-gallery">
            <figure>
                <img src="images/6b.png" alt="Image 1">
            </figure>
            <figure>
                <img src="images/6c.png" alt="Image 1">
            </figure>
            <figure>
                <img src="images/6d.png" alt="Image 1">
            </figure>
        </div>


    </section>


<section id="speed">
        <h2>Text-Conditioned Image-to-image Translation</h2>
        <p>
            We can guide the projection of the image with a text prompt, converting thins into rockets for example:
        </p>


    <div class="gallery large-gallery">
        <figure>
            <img src="images/7a.png" alt="Image 1">
        </figure>
    </div>
    </section>


<section id="speed">
    <h2>Visual Anagrams</h2>
    <p>
        To create visual anagrams we will denoise an image at step t normally with one prompt and at the same time, we will flip the inmage upside down, and denoise with the prompt a different prompt, to get another noise estimate. We can flip the second noise estimate , to make it right-side up, and average the two noise estimates. We can then perform a reverse diffusion step with the averaged noise estimate.
    </p>

    <div class="gallery large_gallery">
        <figure>
            <img src="images/8a.png" alt="Image 2">
        </figure>       
        <figure>
            <img src="images/8b.png" alt="Image 2">
        </figure>

        <figure>
            <img src="images/8c.png" alt="Image 2">
        </figure>
    </div>

    <div class="gallery large_gallery">
        <figure>
            <img src="images/8d.png" alt="Image 2">
        </figure>
        <figure>
            <img src="images/8e.png" alt="Image 2">
        </figure>
    </div>


</section>


<section id="speed">
    <h2>Hybrid Images</h2>
    <p>
        Another cool visual ilussion. The proedure is to create a composite noise estimate epsilon by estimating the noise with two different text prompts, and then combining low frequencies from one noise estimate with high frequencies of the other. 
    </p>

    <div class="gallery large_gallery">
        <figure>
            <img src="images/9a.png" alt="Image 2">
        </figure>       
        <figure>
            <img src="images/9b.png" alt="Image 2">
        </figure>

        <figure>
            <img src="images/9c.png" alt="Image 2">
        </figure>
    </div>

    <div class="gallery large_gallery">
        <figure>
            <img src="images/9d.png" alt="Image 2">
        </figure>
    </div>


</section>


<section id="speed">
    <h2>Training a Single-Step Denoising UNet</h2>
    <p>
        Architecture:
    </p>

    <div class="gallery large_gallery">
        <figure>
            <img src="images/10a.png" alt="Image 2">
        </figure>       
    </div>

    <p>
        Visualize the different noising processes over sigma = [0.0, 0.2, 0.4, 0.5, 0.6, 0.8, 1.0]
    </p>

    <div class="gallery large_gallery">
        <figure>
            <img src="images/10b.png" alt="Image 2">
        </figure>
    </div>

    <p>
        The model denoising at epoch 1, and 5 
    </p>

    <div class="gallery large_gallery">
        <figure>
            <img src="images/10c.png" alt="Image 2">
        </figure>
        <figure>
            <img src="images/10d.png" alt="Image 2">
        </figure>
    </div>

    <p>
        Training loss, model de noising over sigma = [0.0, 0.2, 0.4, 0.5, 0.6, 0.8, 1.0] 
    </p>

    <div class="gallery large_gallery">
        <figure>
            <img src="images/10e.png" alt="Image 2">
        </figure>
        <figure>
            <img src="images/10f.png" alt="Image 2">
        </figure>
    </div>

</section>


<section id="speed">
    <h2>Adding Time Conditioning to UNet</h2>
    <p>
        We need a way to inject scalar t into our UNet model to condition it.
    </p>

     <p>
        Results
    </p>

    <div class="gallery large_gallery">
        <figure>
            <img src="images/11a.png" alt="Image 2">
        </figure>      

        <figure>
            <img src="images/11b.png" alt="Image 2">
        </figure>    
    </div>

    
    <div class="gallery large_gallery">
        <figure>
            <img src="images/11c.png" alt="Image 2">
        </figure>      

        <figure>
            <img src="images/11d.png" alt="Image 2">
        </figure>    
    </div>


</section>

<section id="speed">
    <h2>Adding Class-Conditioning to UNet</h2>
    <p>
       To make the results better and give us more control for image generation, we can also optionally condition our UNet on the class of the digit 0-9. 
    </p>

     <p>
        Results
    </p>

    <div class="gallery large_gallery">
        <figure>
            <img src="images/12a.png" alt="Image 2">
        </figure>      

        <figure>
            <img src="images/12b.png" alt="Image 2">
        </figure>    
    </div>

    
    <div class="gallery large_gallery">
        <figure>
            <img src="images/12c.png" alt="Image 2">
        </figure>      

        <figure>
            <img src="images/12d.png" alt="Image 2">
        </figure>    
    </div>

</section>


<section id="additionals">
    <h2>Coolest thing I learned</h2>
    <p>
    Clasifier free guidance is extremly  cool and strange.
    </p>
</section>


<section id="additionals">
    <h2>Information</h2>
    <p>
        This website contains transitions not captured by the pdf, spesificaly, the title image changes into a high gamma verison and then into the black and white threshold filter version.
    </p>
</section>


    <script src="script.js"></script>
</body>

<script src="script.js"></script>
</html>
