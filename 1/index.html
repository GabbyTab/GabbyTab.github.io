

<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Sergey Prokudin-Gorsky Reconstruction</title>
    <link rel="stylesheet" href="styles.css">
</head>

    
<body>
    <div class="background-container">
        <div class="image-layer image1"></div>
        <div class="image-layer image2"></div>
        <div class="image-layer image3"></div>
    </div>

    <header id="header">
        <div class="title-image">
            <h1>Sergey Prokudin-Gorsky Color Reconstructions V7</h1>
        </div>
    </header>

    <section id="hall-of-fame">
        <h2>Hall of fame</h2>
        <div class="gallery">
            <img src="images/ssim1.png" alt="Image 1">
            <img src="images/r2.png" alt="Image 1">
            <img src="images/r4.png" alt="Image 1">
        </div>
        <p>Emir, SSIM + Rotations + Translations
Church, SSIM + Rotations + Translations + Linear Contrast scaling
Statue, SSIM + Rotations + Translations
.</p>
    </section>

    <section id="Overview">
        <h2>Overview</h2>
        <p>
            The goal of this assignment is to take the digitized Prokudin-Gorskii glass plate images and,
            using image processing techniques, automatically produce a color image with as few visual artifacts as possible. 
            (from the project website)
        </p>
    </section>

    <section id="naive-methods">
        <h2>Naive L2 Methods and Image Pyramids</h2>
        <div class="gallery">
            <img src="images/l21.png" alt="Image 1">
            <img src="images/l22.png" alt="Image 2">
            <img src="images/l23.png" alt="Image 3">
        </div>
       <p>
            <strong> Image Pyramids</strong>
            Image pyramids are used to speed up computations regarding the comparison of two images. The hope is that the image will obtain relevant information/structure to the operation when it is scaled down. There’s a few ways to go about the resizing, for example we could “summarize” a group of pixels by taking their average. I used sk.transform.rescale to create each level of the pyramid.
        </p>
        <p>
            <strong> Cost Function</strong>
            As an initial cost function I went with minimizing the l2 error.
        </p>

        <p>
        <strong> Results</strong>
        Dismal, effectively no images were really aligned correctly, the l2 norm on it’s own is to weak a metric for our desired result
        </p>



    </section>

    <section id="crr">
        <h2>Cross Correlation</h2>
        <div class="gallery">
            <img src="images/cc1.png" alt="Image 1">
            <img src="images/cc2.png" alt="Image 2">
            <img src="images/cc3.png" alt="Image 3">
        </div>
            <p>
        <strong>Cross Correlation</strong>
         I also tried to use Cross Correlation but there was essentialy no imporvment. 
        </p>
    </section>

    <section id="speed">
        <h2>SPEEED UP</h2>
        <p>
        <strong>Parallelism</strong>
        I separated the search function from align and parallelized it using concurrent. I also tried to make a parallel version of np.roll but it wasn't working as desired.

        </p>
        <p>
        <strong>Quality of Life</strong>
            The image pyramid was imporved to allow us to specify the base of the pyramid, change the amount of tranlations/rotations/zooms depending on the level.
        </p>
    </section>

    <section id="objective-functions">
        <h2>Better Objective Functions</h2>
        <div class="gallery">
            <img src="images/ssim1.png" alt="Image 1">
            <img src="images/ssim2.png" alt="Image 1">
            <img src="images/ssim3.png" alt="Image 1">
        </div>
        <p>
            <strong> SSIM </strong>
            introducing Strucutal Similarity Index Measure: SSIM. This meassure takes into account luminance and reflectance and other shananigans. 
            Out preforms l2 and CNN significantly; does not require any aditinal features to align the images correctley but is substantialy increases the runtime.
        </p>
    </section>
        <section id="Bells-whistles">
        <h1>Bells, whistles and all things  things</h1>
    </section>

    <section id="filters">
        <h2>Better Features</h2>
        <div class="gallery">
            <img src="images/re1.png" alt="Image 1">
            <img src="images/be1.png" alt="Image 1">
            <img src="images/ge1.png" alt="Image 1">
            <img src="images/re.png" alt="Image 1">
            <img src="images/be.png" alt="Image 1">
            <img src="images/ge.png" alt="Image 1">

        </div>           

        <div class="center-stage">
            <img src="images/c_emir.png" alt="Center Stage Image"> 
        </div>

        <div class="gallery">
            <img src="images/f1.png" alt="Image 1">
            <img src="images/f2.png" alt="Image 1">
            <img src="images/f3.png" alt="Image 1">
            <img src="images/f4.png" alt="Image 1">
            <img src="images/f5.png" alt="Image 1">
            <img src="images/f6.png" alt="Image 1">


        </div>
        <p>
            <strong> Tricks </strong> 
            the problem with the l2 norm of the raw pixels is that their is a large amount of hypothesis that share low values.
        </p>

        <p>
            If only we could tell the computer to just focus on the emirs beard. 
        </p>

        <p>
            We want to extract usefull features from the mess, preferably somthing that reveals thigs about the undelying objects.
        </p>

        <p>
            When I think image features my mind immediatley jumps to gradients or edge detection.
            but there's simple solution that caputres the idea of what were trying to do. 
            We can use a threshold filter. That is to say, take all the pixels bellow a 
            minimim brightness and set them to 0, the rest to one. 
        </p>

        <p>
            <strong> Results </strong> 
            Maching with a filter and the naive l2 norm results in a program that is much faster than SSIM can can recover almost all of the images
            without issue (except for the most dificult ones like emir)
        </p>

        <p>
            Example of us brightening each of the chanels:
        </p>

    </section>

    <section id="zoom-rotations">
        <h2>Zoom and Rotations</h2>
        <div class="gallery">
            <img src="images/r1.png" alt="Image 1">
            <img src="images/r2.png" alt="Image 1">
            <img src="images/r3.png" alt="Image 1">
        </div>
        <p>After finding a good center, we can scan over a small number of zooms and rotations to find an even better matching.</p>
    </section>


    <section id="contrast-stretching">
        <h2>Contrast Stretching</h2>
        <div class="gallery">
            <img src="images/cl1.png" alt="Image 1">
            <img src="images/cl2.png" alt="Image 1">
            <img src="images/cl3.png" alt="Image 1">
        </div>
        <p>
            some of these images have a "old picture" quality to them (they are 100 years old). I tried to apply linear contrast scaling in hopes of
            making the images sharpper. Linear contrast scaling works by first cliping the brightness values (say 5th to 95th percentile) and then stretching
            the values in between linearly across the new range. Here are three picture of the church with linscale, (10, 98) (10, 90) (20, 100). Note that as 
            the range get's smaller a larger group of pixels go to the two extreemes (white/black) and the image begins to pop.
            
        </p>
    </section>

    <section id="balancing-techniques">
        <h2>White Balancing </h2>
        <div class="gallery">
            <img src="images/l25.png" alt="Image 4">
            <img src="images/wb1.png" alt="Image 7">
            <img src="images/wb2.png" alt="Image 7">
            <img src="images/f5.png" alt="Image 7">
            <img src="images/wb3.png" alt="Image 7">
            <img src="images/wb4.png" alt="Image 7">

        </div>
        <p>Estimate the iluminant map, try to counter act the iluminant map, the first row corresponds to avg, the second to max./p>
    </section>
    

    <section id="manual-techniques">
        <h2>Manual Historical Shenanigans</h2>
        <div class="gallery">
            <img src="images/f4.png" alt="Image 7">
            <img src="images/h1.png" alt="Image 1">
            <img src="images/h2.png" alt="Image 1">
        </div>
        <p>
            This approach is very limited due to the level of guess work involved but I still think it is both creative and interesting enough to include.
            
            The monastary in the monastary picture still stands and can be found in google maps. Using photos of the location, 
            we can estimate where the photo was taken, the bearing of the
            photographer and the distance from the photographer to one of the trees on the left of the photo and it's coressponding shadow.
            using an estimate of the camara's dimensions and a google search of the aproximate distance between the photographer and the tree, 
            we can guesss the height and bearing of the shadow of the tree. Now we have a solar angle. We can crossinformaiton the solar angle in 
            a solar calculator on that location in the year 1910 to guess the aproximate illuminante of the sunlight on the day when the picture was taken. 
            Then we can try to counteact that iluminant.</p>
    </section>

    <section id="retinex">
        <h2>Retinex</h2>
        <div class="gallery">
            <img src="images/retinex1.jpg" alt="Image 1">
            <img src="images/retinex2.jpg" alt="Image 1">

        </div>
        <p>Finally I attempted to implement and apply retinex, but for the life of me it did not work :( 
        I don't know it it's because these images don't meet the gray world assumption at all, or if i'm just
        having trouble with the tif format. Here is my couple of attempts.</p>
    </section>

    <section id="future-techniques">
        <h2>Improvments</h2>
        <p>Speculation on future techniques...</p>
    </section>

    
    <section id="references">
        <h2>References</h2>
        <p>
            Wikipedia Articles seen:
            blogs seen:
        </p>
    </section>


    <script src="script.js"></script>
</body>

<script src="script.js"></script>
</html>
