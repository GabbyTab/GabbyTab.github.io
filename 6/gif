

<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Final project (first one)</title>
    <link rel="stylesheet" href="styles.css">
</head>

    
<body>
    <div class="background-container">
        <div class="image-layer image1"></div>
        <div class="image-layer image2"></div>
        <div class="image-layer image3"></div>
    </div>


    <header id="header">
        <div class="title-image">
            <h1>Lightfield Camera</h1>
        </div>
    </header>


    <section id="Overview">
        <h2>Project A</h2>
        <p>
        Reproduce some of the effects from the paper by  Ng et al using real lightfield data. 
        </p>
        <p>
            Note a link to my second project at the bottom.
        </p>
    </section>
    
    <section id="hall-of-fame">
        <h2>Part 1) Depth Refocusing</h2>
        <h3>Simulating a camera focusing at different depths using all the grid images. </h3>

               
        <p>
           This is a really clever trick that uses parallax. Object which are far away from the camera move less when the camera moves, and they  tend to keep the optical same axis, than objects that are closer. By averaging the images of the lightfield grid without shifting, we can focus on distant objects since they stay relatively still. What’s cool is that we can manipulate this effect by shifting the images appropriately and then averaging.
        </p>
            
        <p>
            To achieve this, we compute shifts (dx, dy) from the camera positions provided in the dataset. By scaling these shifts with a scalar value, we control the focus depth, allowing us to generate images that simulate focusing on objects at different distances.
        </p>
        
        <div class="gallery medium-gallery">   
            <figure>
                <img src="images/refocused_images_1.gif" alt="Image 1">
            </figure>
        </div>
        
         <p>
            20 images, scalar from -0.1 to 0.5
        </p>
        <button id="reset-button">Reset GIFs</button>

       
    </section>



    <section id="naive-methods">
        <h2>Aperture Adjustment</h2>
        <h3>Simulating a camera of different apertures focusing on a common point. </h3>

        <p> 
            The reason averaging a large number of images sampled over the grid perpendicular to the optical axis mimics a camera with a larger aperture is: decreasing the aperture is effectively the same as letting less light in with bigger angles. Averaging all grid images is equivalent to allowing light from all directions, mimicking a fully open aperture.        </p>

        <p>Conversely, to simulate a smaller aperture, we just include only the images closest to the optical center in our averaging process (within some radius). This reduces the effective aperture size, narrowing the range of angles contributing to the image./p>


        <div class="gallery medium-gallery">   
            <figure>
                <img src="images/reappature_images_1.gif" alt="Image 1">
            </figure>
        </div>

        <button id="reset-button">Reset GIFs</button>

           <p> 
20 images with radius from 0 to 10
           </p>


      

        
    </section>




    <section id="speed">
        <h2>What I learned</h2>

        <p>
Plenoptic cameras are amazing. With lightfields, we can approximate multiple views from a single setup. Parallax is not just a cool visual effect but also a useful feature that enables depth refocusing and aperture adjustment. FInally the intuition for Depth Refocusing is rooted in the very simple effects of averaging that we learned earlier in the semester.        </p>


        <h2>Conclusion</h2>

        <p>
This project demonstrated how lightfields enable complex visual effects, such as depth refocusing and aperture simulation, through simple operations like shifting and averaging. It built intuition on how plenoptic cameras work and showed how important precise image captures are when working with lightfields.
        </p>


            
    </section>


       <section id="charicatures">
       <h2>Bells and Whistles: Using Real Data</h2>

        <p> 

I tried several examples, and the easiest setup I could manage was using a chessboard at home. Unfortunately, I was unable to fully recreate the lightfield effects. I believe the challenge lies in achieving the required precision.
The paper specifies that the images must be captured over a plane orthogonal to the optical axis, with consistent spacing between them. Without specialized equipment, it’s extremely difficult to maintain equal spacing and ensure orthogonality between the image plane and the optical axis. As a result, the subtle parallax cues needed for these effects were missing from my images.
        </p>

           <p>Left most vie, middle view, rightmosts view</p>
            <div class="gallery medium-gallery">   
            <figure>
                <img src="images/chess_1.png" alt="Image 1">
            </figure>
                  <figure>
                <img src="images/chess_2.png" alt="Image 1">
            </figure>
                  <figure>
                <img src="images/chess_3.png" alt="Image 1">
            </figure>
        </div>
           
           
        <div class="gallery medium-gallery">   
            <figure>
                <img src="images/refocused_images.gif" alt="Image 1">
            </figure>
        </div>

        <button id="reset-button">Reset GIFs</button>
            
    </section>

<section id="additionals">
    <h2>Other Final project Link:</h2>

    <p> <a href="https://inst.eecs.berkeley.edu/~cs194-26/fa17/hw/proj5/" target="https://inst.eecs.berkeley.edu/~cs194-26/fa17/hw/proj6/">CS194 Project Page</a> </p>
  
</section>
<section id="additionals">
    <h2>Information</h2>

   
    <p>
        This website contains transitions not captured by the pdf, spesificaly, the title image changes into a high gamma verison and then into the black and white threshold filter version.
    </p>
</section>

    <section id="additionals">
    <h2>Sources</h2>
    <p>
      https://inst.eecs.berkeley.edu/~cs194-26/fa17/hw/proj5/
    </p>
            <p>
https://graphics.stanford.edu/papers/lfcamera/lfcamera-150dpi.pdf
            </p>
</section>


    <script src="script.js"></script>
</body>

<script src="script.js"></script>
</html>
